{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8RsFXXjeZ4u",
        "outputId": "d127b0c8-ffb8-4d47-ce5e-68517a10adff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Oqny6zmz4_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNDknI3w69qz",
        "outputId": "2432dd97-542d-4fd9-e20a-e035f1953b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting...\n",
            "Loaded dataset Demo/Labelled/SmallLabelled.csv for column Latitude\n",
            "Formatting Complete Demo/Labelled/SmallLabelled.csv for column Latitude\n",
            "Loaded dataset Demo/Labelled/SmallLabelled.csv for column Longitude\n",
            "Formatting Complete Demo/Labelled/SmallLabelled.csv for column Longitude\n",
            "Loaded dataset Demo/Labelled/SmallLabelled.csv for column Cog\n",
            "Formatting Complete Demo/Labelled/SmallLabelled.csv for column Cog\n",
            "Loaded dataset Demo/Labelled/SmallLabelled.csv for column Sog\n",
            "Formatting Complete Demo/Labelled/SmallLabelled.csv for column Sog\n",
            "Loaded dataset Demo/Labelled/LargeLabelled.csv for column Latitude\n",
            "Formatting Complete Demo/Labelled/LargeLabelled.csv for column Latitude\n",
            "Loaded dataset Demo/Labelled/LargeLabelled.csv for column Longitude\n",
            "Formatting Complete Demo/Labelled/LargeLabelled.csv for column Longitude\n",
            "Loaded dataset Demo/Labelled/LargeLabelled.csv for column Cog\n",
            "Formatting Complete Demo/Labelled/LargeLabelled.csv for column Cog\n",
            "Loaded dataset Demo/Labelled/LargeLabelled.csv for column Sog\n",
            "Formatting Complete Demo/Labelled/LargeLabelled.csv for column Sog\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Using the trained models to make predictions\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.src.saving.saving_api import load_model\n",
        "\n",
        "def normalise_data(data: list) -> list:\n",
        "    \"\"\"\n",
        "    Performs min max normalisation on the list.\n",
        "    :param data: The data that is going to be normalised\n",
        "    :return: list returns a normalises list\n",
        "    \"\"\"\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    normalised = (data - min_val) / (max_val - min_val)\n",
        "    return normalised\n",
        "\n",
        "\n",
        "def pre_processing(pos_file_name: str, y_column: str, extra_x_columns: list = None,\n",
        "                   window_size: int = 5) -> tuple[list, list]:\n",
        "    \"\"\"\n",
        "    Pre-processes the positional dataset ready for training or validation\n",
        "    :param pos_file_name: The position file to load from\n",
        "    :param y_column: The column to train on, the y list\n",
        "    :param extra_x_columns: The extra columns to include within the x list\n",
        "    :param window_size: The number of positions with each window\n",
        "    :return: tuple[list, list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Load training data from CSV file\n",
        "    dataframe = pd.read_csv(pos_file_name)\n",
        "\n",
        "    print(f\"Loaded dataset {pos_file_name} for column {y_column}\")\n",
        "\n",
        "    # Sort and convert datetime into seconds since Unix Epoch\n",
        "    dataframe = dataframe.sort_values(by=[\"UserID\", \"UnixReceiveTime\"])\n",
        "\n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    x_columns = [\"Cog\", \"Sog\", \"Longitude\",\n",
        "                 \"Latitude\", \"UnixReceiveTime\"]\n",
        "    if extra_x_columns is not None:\n",
        "        x_columns.extend(extra_x_columns)\n",
        "\n",
        "    # Converts the course to radians\n",
        "    dataframe[\"Cog\"] = np.radians(dataframe[\"Cog\"])\n",
        "\n",
        "    for _, vessel in dataframe.groupby(\"UserID\"):\n",
        "        vessel = vessel.reset_index()\n",
        "        # Adds the columns to the x list\n",
        "        x_section = [vessel.iloc[index:index + window_size]\n",
        "                     [x_columns].values.tolist()\n",
        "                     for index in range(len(vessel) - window_size)]\n",
        "\n",
        "        # Adds the time since the first position to the x list\n",
        "        for x_index in range(len(x_section)):\n",
        "            for sequence_index in range(0, window_size):\n",
        "                x_section[x_index][sequence_index][4] = abs(dataframe.at[x_index + sequence_index,\n",
        "                                                                         \"UnixReceiveTime\"] -\n",
        "                                                            x_section[x_index][sequence_index][4])\n",
        "\n",
        "        x_list.extend(x_section)\n",
        "\n",
        "        y_section = vessel.iloc[window_size:][y_column].values.flatten().tolist()\n",
        "        y_list.extend(y_section)\n",
        "\n",
        "    x_array = np.array(x_list)\n",
        "    y_array = np.array(y_list)\n",
        "\n",
        "    # Normalisation\n",
        "    for index in range(x_array.shape[-1]):\n",
        "        x_array[:, :, index] = normalise_data(x_array[:, :, index])\n",
        "\n",
        "    print(f\"Formatting Complete {pos_file_name} for column {y_column}\")\n",
        "    return x_array, y_array\n",
        "\n",
        "def calculate_mae(prediction: list, actual: list) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the mean absolute error of the two lists.\n",
        "    :param prediction: a list of predicted data\n",
        "    :param actual: a list of actual data\n",
        "    :return: float - the mean absolute error\n",
        "    \"\"\"\n",
        "\n",
        "    act_len = len(actual)\n",
        "    if act_len != len(prediction):\n",
        "        raise ValueError(\"The lengths of the two lists must be the same.\")\n",
        "\n",
        "    error_sum = sum(abs(act - pred) for act, pred in zip(actual, prediction))\n",
        "    mae = error_sum / act_len\n",
        "    return mae\n",
        "\n",
        "\n",
        "def calculate_mse(prediction: list, actual: list) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the mean squared error of the two lists.\n",
        "    :param prediction: a list of predicted data\n",
        "    :param actual: a list of actual data\n",
        "    :return: float - the mean squared error\n",
        "    \"\"\"\n",
        "\n",
        "    act_len = len(actual)\n",
        "    if act_len != len(prediction):\n",
        "        raise ValueError(\"The lengths of the two lists must be the same.\")\n",
        "\n",
        "    squared_diff = [(act - pred) ** 2 for act, pred in zip(actual, prediction)]\n",
        "    mse = sum(squared_diff) / act_len\n",
        "    return mse\n",
        "\n",
        "\n",
        "def print_stats(prediction: list, actual: list,\n",
        "                column: str, save_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Writes the mean squared error and mean absolute error between the prediction and actual lists.\n",
        "    This is written to the save file.\n",
        "    :param prediction: a list of predicted data\n",
        "    :param actual: a list of actual data\n",
        "    :param column: the column that is the actual or predicted data\n",
        "    :param save_name: the file path to save the stats to\n",
        "    :return: none\n",
        "    \"\"\"\n",
        "\n",
        "    mae = calculate_mae(prediction, actual)\n",
        "    mse = calculate_mse(prediction, actual)\n",
        "    with open(save_name, 'a') as file:\n",
        "        file.write(f\"Column: {column}, MAE: {mae}, MSE: {mse}\\n\")\n",
        "\n",
        "\n",
        "def predict(pos_file_name: str, lat_model: str, lon_model: str,\n",
        "            cog_model: str, sog_model: str, stats_save_file: str,\n",
        "            pred_save_file: str, windows_size=7) -> None:\n",
        "    \"\"\"\n",
        "    Uses the trained models to make predictions\n",
        "    :param pos_file_name: the position file to load from\n",
        "    :param lat_model: the trained keras latitude model\n",
        "    :param lon_model: the trained keras longitude model\n",
        "    :param cog_model: the trained keras course model\n",
        "    :param sog_model: the trained keras speed model\n",
        "    :param stats_save_file: the file path to save the stats file to\n",
        "    :param pred_save_file: the file path to save the predictions to\n",
        "    :param windows_size: the size of the window (must match the trained keras file)\n",
        "    :return: none\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocesses the prediction files\n",
        "    lat_x, lat_y = pre_processing(pos_file_name, \"Latitude\",\n",
        "                                  window_size=windows_size,\n",
        "                                  extra_x_columns=[\"RateOfTurn\"])\n",
        "    lon_x, lon_y = pre_processing(pos_file_name, \"Longitude\",\n",
        "                                  window_size=windows_size,\n",
        "                                  extra_x_columns=[\"RateOfTurn\"])\n",
        "    cog_x, cog_y = pre_processing(pos_file_name, \"Cog\",\n",
        "                                  window_size=windows_size,\n",
        "                                  extra_x_columns=[\"Labels\",\n",
        "                                                   \"NavigationalStatus\"])\n",
        "    sog_x, sog_y = pre_processing(pos_file_name, \"Sog\",\n",
        "                                  window_size=windows_size,\n",
        "                                  extra_x_columns=[\"Labels\",\n",
        "                                                   \"NavigationalStatus\"])\n",
        "\n",
        "    # Using the saved models, loads up the trained models\n",
        "    lat_model = load_model(lat_model)\n",
        "    lon_model = load_model(lon_model)\n",
        "    cog_model = load_model(cog_model)\n",
        "    sog_model = load_model(sog_model)\n",
        "\n",
        "    # Creates predictions using the trained models\n",
        "    pred_lat = lat_model.predict(lat_x, verbose=0).flatten().tolist()\n",
        "    pred_lon = lon_model.predict(lat_x, verbose=0).flatten().tolist()\n",
        "    pred_cog = cog_model.predict(cog_x, verbose=0).flatten().tolist()\n",
        "    pred_sog = sog_model.predict(cog_x, verbose=0).flatten().tolist()\n",
        "\n",
        "    # Prints the results comparing predictions to actual values\n",
        "    # Saves these to csv files\n",
        "    print_stats(pred_lat, lat_y, \"Lat\", stats_save_file)\n",
        "    print_stats(pred_lon, lon_y, \"Lon\", stats_save_file)\n",
        "    print_stats(pred_cog, cog_y, \"Cog\", stats_save_file)\n",
        "    print_stats(pred_sog, sog_y, \"Sog\", stats_save_file)\n",
        "\n",
        "    # Creates a csv file of the predictions\n",
        "    predictions = {\"Sog\": pred_sog, \"Longitude\": pred_lon,\n",
        "                   \"Latitude\": pred_lat, \"Cog\": pred_cog}\n",
        "    pred_dataframe = pd.DataFrame.from_dict(predictions)\n",
        "    pred_dataframe.to_csv(pred_save_file, index=False)\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nPredicting...\")\n",
        "\n",
        "    predict(\"Demo/Labelled/SmallLabelled.csv\",\n",
        "            \"Models/SmallModelLatitude.keras\",\n",
        "            \"Models/SmallModelLongitude.keras\",\n",
        "            \"Models/SmallModelCog.keras\",\n",
        "            \"Models/SmallModelSog.keras\",\n",
        "            \"Demo/Results/SmallLog.csv\",\n",
        "            \"Demo/Results/SmallPredictions.csv\")\n",
        "\n",
        "    predict(\"Demo/Labelled/LargeLabelled.csv\",\n",
        "            \"Models/LargeModelLatitude.keras\",\n",
        "            \"Models/LargeModelLongitude.keras\",\n",
        "            \"Models/LargeModelCog.keras\",\n",
        "            \"Models/LargeModelSog.keras\",\n",
        "            \"Demo/Results/LargeLog.csv\",\n",
        "            \"Demo/Results/LargePredictions.csv\")\n",
        "\n",
        "main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}